{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Driven Protein Engineering \n",
    "- Use of a machine learning approach to use additional data to support the design of novel enzymes\n",
    "- Focus on a training a small dataset for 1st model then to be used on secondary dataset for model improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Import Libraries'\n",
    "\n",
    "#Python Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dupont Packages\n",
    "from prolerep.analysis.utils import read_csv_from_uri\n",
    "import prolerep.analysis.utils as utils\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\")\n",
    "\n",
    "#Scikit Packages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\\\n",
    "\n",
    "#Tensorflow Packages\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, activations\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "- *Upload df and select sequences (can be done with any particular dataframe)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Upload original dataset'\n",
    "galapagos_stability_df = utils.read_csv_from_s3(\"s3://prolerep/datasets/galapagos_stability_df_reduced.csv\") \n",
    "#galapagos_stability_df = galapagos_stability_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>stability</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-AQSVPWGISRVQAPAAH-NRGLRGSGVKVAVLDTGI-STHPDLNI...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-AQQVPYGVSQIKAPALH-EQGYTGQNVKVAVIDTGIDSSHPDLKV...</td>\n",
       "      <td>0.46</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-AQSVPWGIRRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-AQTVPWGISRVQAPAAH-NRGLTGAGVKVSVLDTGI-STHPDLNI...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-AQSVPYGVSQIKAPALH-SQGYTGSNVKVAVIDTGIDSSHPDLKV...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-AQSVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-AQQVPYGVSQIKAPALH-EQGYYGSNVKVAVIDSGIDSSHPDLKV...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-AQSVPYGVSQIKAPALH-SQGYTGSNVKVAVIDTGIDSSHPDLKV...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-AQQVPYGVEQIKAPALH-SQGYTGQNVKVAVIDTGIDSSHPDLKV...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-AQSVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sequence  stability  \\\n",
       "0     -AQSVPWGISRVQAPAAH-NRGLRGSGVKVAVLDTGI-STHPDLNI...       0.00   \n",
       "1     -AQQVPYGVSQIKAPALH-EQGYTGQNVKVAVIDTGIDSSHPDLKV...       0.46   \n",
       "2     -AQSVPWGIRRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...       0.34   \n",
       "3     -AQTVPWGISRVQAPAAH-NRGLTGAGVKVSVLDTGI-STHPDLNI...       0.95   \n",
       "4     -AQSVPYGVSQIKAPALH-SQGYTGSNVKVAVIDTGIDSSHPDLKV...       0.60   \n",
       "...                                                 ...        ...   \n",
       "1995  -AQSVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...       0.02   \n",
       "1996  -AQQVPYGVSQIKAPALH-EQGYYGSNVKVAVIDSGIDSSHPDLKV...       0.29   \n",
       "1997  -AQSVPYGVSQIKAPALH-SQGYTGSNVKVAVIDTGIDSSHPDLKV...       0.66   \n",
       "1998  -AQQVPYGVEQIKAPALH-SQGYTGQNVKVAVIDTGIDSSHPDLKV...       0.06   \n",
       "1999  -AQSVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLNI...       1.00   \n",
       "\n",
       "      temperature  \n",
       "0            50.0  \n",
       "1            42.0  \n",
       "2            46.0  \n",
       "3            45.0  \n",
       "4            50.0  \n",
       "...           ...  \n",
       "1995         45.0  \n",
       "1996         42.0  \n",
       "1997         46.0  \n",
       "1998         60.0  \n",
       "1999         46.0  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galapagos_stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Obtain Protein Sequences'\n",
    "galapagos_seqs = galapagos_stability_df['sequence'].str.replace(\"-\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings\n",
    "\n",
    "- *Load embedded sequences from .tfrecord file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3840)\n"
     ]
    }
   ],
   "source": [
    "file = '/home/john/Dupont_Internship/Transfer_Learning/Galapagos_Data/my_galapagos_reduced_sequences.tfrecord'\n",
    "parse_float_tensor = lambda x: tf.io.parse_tensor(x, out_type=tf.float64)\n",
    "dataset = (\n",
    "    tf.data.TFRecordDataset([file])\n",
    "    .map(parse_float_tensor)\n",
    "    .batch(len(galapagos_seqs)))\n",
    "\n",
    "galapagos_embeddings = next(iter(dataset))\n",
    "print(galapagos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(df, embeddings):\n",
    "    \n",
    "    '''Create a Dictionary with Multiple \n",
    "    Values paired to single key\n",
    "    \n",
    "    Returns: Dictionary with Multiple Values'''\n",
    "    \n",
    "    #Create needed arrays\n",
    "    temperature = df['temperature']\n",
    "    temp_array = np.array(temperature)\n",
    "    embeddings_array = np.array(embeddings)\n",
    "\n",
    "    embedded_dict = {}\n",
    "    \n",
    "    for index, (value1, value2) in enumerate(zip(embeddings_array, temp_array)):\n",
    "        embedded_dict[index] = [value1, value2]\n",
    "\n",
    "    return embedded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_df(original_df, embeddings):\n",
    "    \n",
    "    '''Create a dataframe with features to be used in NN\n",
    "    \n",
    "    Returns: Modified Dataframe'''\n",
    "    \n",
    "    embedded_dict = create_dictionary(original_df, embeddings)\n",
    "    \n",
    "    embeddings_list = []\n",
    "    temperature_list = []\n",
    "    for i in embedded_dict.values():\n",
    "        embeddings_list.append(i[0])\n",
    "        temperature_list.append(i[1])\n",
    "    \n",
    "    index = [str(i) for i in range(0, len(embeddings_list))]\n",
    "    features_df = pd.DataFrame(embeddings_list, index=index)\n",
    "    features_df['temperature'] = temperature_list\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dict = create_dictionary(galapagos_stability_df, galapagos_embeddings)\n",
    "features_df = modify_df(galapagos_stability_df, galapagos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "- Preparing the data before modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Split and Standardize the Dataset'\n",
    "def data_prep(original_df, features_df):\n",
    "    'Standardize The Data'\n",
    "    x = features_df\n",
    "    x = np.array(x)\n",
    "    y = original_df['stability']\n",
    "    y = y.values\n",
    "\n",
    "    # Split Data in train and validation\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.25, random_state = 6)\n",
    "\n",
    "    return x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.98100138, -2.34005857, -2.09497738, ...,  2.47909617,\n",
       "         1.24270701, 60.        ],\n",
       "       [-1.99232936, -2.40292597, -1.94223857, ...,  2.60929155,\n",
       "         1.25136018, 68.        ],\n",
       "       [-1.88469315, -2.37894297, -1.84657502, ...,  2.43665838,\n",
       "         1.19955122, 60.        ],\n",
       "       ...,\n",
       "       [-1.84089506, -2.74671292, -2.0166223 , ...,  1.92245877,\n",
       "         2.11539054, 60.        ],\n",
       "       [-1.84819281, -2.36005425, -1.66958201, ...,  2.35021377,\n",
       "         1.24997282, 60.        ],\n",
       "       [-2.01986623, -2.46019411, -1.93254495, ...,  2.61112523,\n",
       "         1.30350792, 68.        ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = data_prep(galapagos_stability_df, features_df)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Subsetting Dataset'\n",
    "# first_embeddings = galapagos_embeddings[:1000]\n",
    "# first_df = galapagos_stability_df[:1000]\n",
    "# second_embeddings = galapagos_embeddings[1000:]\n",
    "# second_df = galapagos_stability_df[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_model():\n",
    "\n",
    "    # import BatchNormalization\n",
    "    #from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "\n",
    "    # we can think of this chunk as the input layer\n",
    "    model.add(layers.Dense(128, input_shape = (x_train.shape[1],)))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Activation(activations.relu))\n",
    "\n",
    "    # we can think of this chunk as the hidden layer    \n",
    "    model.add(layers.Dense(128))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Activation(activations.relu))\n",
    "\n",
    "    # we can think of this chunk as the output layer\n",
    "    model.add(Dense(1))\n",
    "    #model.add(layers.Activation(activations.softplus))\n",
    "    \n",
    "    # setting up the optimization of our weights \n",
    "    model.compile(loss='mean_squared_error', optimizer = Adam(lr = 0.001), metrics=['mean_absolute_error'])\n",
    "    \n",
    "    # ANN Summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 128)               491776    \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 509,441\n",
      "Trainable params: 508,929\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = normalized_model()\n",
    "history = model.fit(x_train, y_train, batch_size = 25,\n",
    "                    epochs = 50, verbose = 0 ,validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Initialising the ANN\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(units = 128, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units = 256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "   \n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "    # Compile the ANN\n",
    "    model.compile(loss='mean_squared_error', optimizer = Adam(lr = 0.001), metrics=['mean_absolute_error'])\n",
    "\n",
    "    # ANN Summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Initialising the ANN\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(units = 128, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units = 128, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.3))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1, activation = 'softplus'))\n",
    "\n",
    "    # Compile the ANN\n",
    "    model.compile(loss='mean_squared_error', optimizer = Adam(lr = 0.001), metrics=['mean_absolute_error'])\n",
    "\n",
    "    # ANN Summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 128)               491776    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 509,441\n",
      "Trainable params: 508,929\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Call Model\n",
    "model = build_model()\n",
    "#Train Model\n",
    "history = model.fit(x_train, y_train, batch_size = 25, epochs = 100, verbose = 0 ,validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This callback will stop the training when there is no improvement in the validation loss for 10 consecutive epochs.\n",
    "\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(x_train, y_train, epochs=30, batch_size=50, callbacks=[callback], \n",
    "# verbose=1, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=1)\n",
    "    \n",
    "print('Score loss:', score)\n",
    "\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test MAE:', round(score[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Interval Size Distribution\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss', fontsize = 30)\n",
    "plt.ylabel('Loss', fontsize = 25)\n",
    "plt.xlabel('Epoch No.',  fontsize = 25)\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(y_valid, y_pred)\n",
    "plt.suptitle('Model Predictions', fontsize=30)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'k--', lw=4)\n",
    "plt.xlabel('True', fontsize = 25)\n",
    "plt.ylabel('Predictions', fontsize = 25)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Predictions '\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_valid, color = 'red', label = 'Real data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Error Distribution'\n",
    "# plt.figure(figsize=(16,8))\n",
    "# error = y_pred - y_valid\n",
    "# plt.hist(error, bins = 25)\n",
    "# plt.xlabel(\"Prediction Error\")\n",
    "# _ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nn_model(model, name):\n",
    "    \"\"\"\n",
    "    Saves the model and weights to current local directory.\n",
    "\n",
    "    :param model: the model of the network\n",
    "    :param name: the name of the files used\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(name + '.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(name + '.h5')\n",
    "    print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nn_model(name):\n",
    "    \"\"\"\n",
    "    Loads the saved model.\n",
    "\n",
    "    :param name: the name of the files\n",
    "    :return: the loaded model\n",
    "    \"\"\"\n",
    "    json_file = open(name + '.json', 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(name + '.h5') #corresponds to saved model above\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
