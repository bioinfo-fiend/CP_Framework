{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Predictions for ML Models (Dupont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook dedicated to the python implementation of the conformal prediction framework for ml models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index**\n",
    "* [Library Imports](#library_imports)\n",
    "* [Enviroments & Models Function](#environment_models) \n",
    "* [Data Split Function](#data_split)\n",
    "* [NonConformist Class](#nonconformal_class)\n",
    "* [Loading Model and Environments](#Loading_Model)\n",
    "* [Data Setup](#data_setup)\n",
    "* [Training and Calibration Procedure](#training_calibration)\n",
    "* [Efficiency and Validity](#efficiency_validity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library_imports'></a>\n",
    "## Library Imports\n",
    "\n",
    "Import necessary modules for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import prolerep.analysis.utils as utils\n",
    "import mlflow.pyfunc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='environment_models'></a>\n",
    "## Load Environment and Models Function\n",
    "* Function comitted to preparing the environment variables and model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prep(env):\n",
    "    dotenv.load_dotenv(env)\n",
    "    runs = mlflow.search_runs(4) #ExperimentID:(4:Expression,13:Activity,14:Stability)\n",
    "    cols = [\"run_id\", \"params.model_name\", \"metrics.valid_r_square\",\n",
    "        \"metrics.train_r_square\", \"params.prepared_dataset_uri\"]\n",
    "    best = (\n",
    "    runs\n",
    "    .sort_values(\"metrics.valid_r_square\", ascending=False)\n",
    "    .groupby(\"params.model_name\")\n",
    "    .head(n=1)\n",
    "    [cols]\n",
    "    .set_index(\"params.model_name\"))    \n",
    "    model = mlflow.pyfunc.load_model(f\"runs:/{best.loc['PLSRun'].run_id}/logged_model\")\n",
    "    print(\"Environment and Models have been loaded\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_split'></a>\n",
    "## Data Split Function\n",
    "* Function dedicated to splitting original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df):\n",
    "    train = df.loc[df['split'] == 'train']\n",
    "    valid = df.loc[df['split'] == 'valid']\n",
    "    X_test = valid.iloc[:,:-1]\n",
    "    y_test = valid.iloc[:,-1] \n",
    "    X_train = train.iloc[:,:-1] \n",
    "    y_train = train.iloc[:,-1] \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train, y_train, test_size =0.2)\n",
    "    print(\"Data has been split\")\n",
    "    print(\"X_train and y_train shape: \"+ str(X_train.shape) + str(y_train.shape))\n",
    "    print(\"X_cal and y_cal shape: \"+ str(X_cal.shape) + str(y_cal.shape))\n",
    "    print('{} instances, {} features, {} classes'.format(y_train.size,\n",
    "                                                   X_train.shape[1],\n",
    "                                                   np.unique(y_train).size))\n",
    "    return X_test, y_test, X_train, y_train, X_cal, y_cal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nonconformal_class'></a>\n",
    "## NonConformist Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonConformist():\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def underlying_fit (self, X_train, y_train):\n",
    "        '''\n",
    "        Train underlying model on proper training data\n",
    "            \n",
    "        @Params\n",
    "        X_train: has shape (n_train, n_features)\n",
    "        y_train: has shape (n_train)\n",
    "        \n",
    "        -------\n",
    "        Returns:\n",
    "        \n",
    "        A fitted model\n",
    "        '''\n",
    "        \n",
    "        self.model.fit(X_train,y_train)\n",
    "        \n",
    "        print(\"Model has been fitted\")\n",
    "        \n",
    "    def calibration_predict(self, X_cal):\n",
    "        '''\n",
    "            Obtain predictions from the underlying model using X_cal data. \n",
    "            Returns an output of predicted real values as numpy.array of shape (n_test)\n",
    "            \n",
    "        @params\n",
    "        X_cal: numpy array has shape (n_train, n_features)\n",
    "        \n",
    "        --------\n",
    "        Returns:\n",
    "        \n",
    "        Predictions: Set of predictions based from the calibration data\n",
    "        '''\n",
    "        calibration_predictions = self.model.predict(X_cal)\n",
    "\n",
    "        print(\"Calibration Predictions Established\")\n",
    "        return calibration_predictions\n",
    "                     \n",
    "    def apply_nonconformity(self, calibration_predictions, y_cal):\n",
    "        '''\n",
    "        Calculates absolute error nonconformity scores for calibration set.\n",
    "        For each correct output in ``y``, nonconformity is defined as\n",
    "        math::\n",
    "        | y_i (predicted labels) - y^_i (true labels) |     \n",
    "       \n",
    "        @params\n",
    "        true_labels is a numpy array of (true) labels \n",
    "        predictions is a numpy array of predicted labels\n",
    "        \n",
    "        Returns:\n",
    "        Calibration scores: numpy array of shape [n_samples]\n",
    "        Non conformity scores of the samples\n",
    "        '''\n",
    "               \n",
    "        true_labels = np.array(y_cal)\n",
    "        calibration_predictions = calibration_predictions.flatten()\n",
    "        \n",
    "        conformity_scores = np.abs(calibration_predictions - true_labels)\n",
    "        conformity_scores = np.sort(conformity_scores)[::-1] #sort in descending order\n",
    "        print(\"Calibration Conformal Scores Obtained\")\n",
    "        \n",
    "        return conformity_scores\n",
    "    \n",
    "    def apply_inverse(self, conformity_scores, significance):\n",
    "        ''' \n",
    "        Function applies the partial inverse of the nonconformity function\n",
    "        to calculate the prediction intervals where:\n",
    "               \n",
    "        @params\n",
    "        calibration_scores: Nonconformity scores obtained from the conformal predictor [n_calibration_samples]\n",
    "        Significance: Float value between 0-1 (i.e. 0.05)\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        Interval: Numpy array of shape [n_samples, 2] that determines\n",
    "        the min and max interval boundaries for each prediction\n",
    "        '''\n",
    "        \n",
    "        border = int(np.floor(significance * (conformity_scores.size + 1))) - 1\n",
    "        border = min(max(border, 0), conformity_scores.size - 1)\n",
    "        \n",
    "        return np.vstack([conformity_scores[border], conformity_scores[border]])\n",
    "    \n",
    "    def test_predict(self, X_test):\n",
    "        '''\n",
    "            Obtain predictions from the underlying model using X_test data. \n",
    "            Returns an output of predicted real values as numpy.array of shape (n_test)\n",
    "            \n",
    "        @params\n",
    "        X_test: numpy array has shape (n_train, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        Predictions: Set of predictions based from the test data\n",
    "        '''\n",
    "        test_predictions = self.model.predict(X_test)\n",
    "\n",
    "        print(\"Test Predictions Established\")\n",
    "        \n",
    "        return test_predictions\n",
    "\n",
    "    def conformal_predictions(self, X_test, conformity_scores, significance):\n",
    "        \"\"\"\n",
    "        Function will construct the prediction intervals \n",
    "        for a set of test examples. \n",
    "        \n",
    "        This applies the partial inverse nonconformity function\n",
    "        to each prediction from the underlying model, thus\n",
    "        resulting in a prediction interval for each test pattern.\n",
    "\n",
    "        @params\n",
    "        ----------\n",
    "        X_test: Numpy array of shape [n_samples, n_features]\n",
    "        Inputs of test patterns for which to predict final output values\n",
    "\n",
    "        Significance: Considered a float between 0 and 1; determimned as \n",
    "        the maximum allowed error rate of predictions.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99]\n",
    "        When significance value is a float between 0 and 1, then p \n",
    "        contains the prediction intervals (minimum and maximum boundaries)\n",
    "        for the set of test patterns at the chosen significance level.\n",
    "        \"\"\"\n",
    "        n_test = X_test.shape[0] #Takes shape of X_test row number\n",
    "        norm = np.ones(n_test) #Returns an array of X_test shape, filled with ones.\n",
    "        test_predictions = self.test_predict(X_test) #Predictions from test data\n",
    "        test_predictions = test_predictions.flatten() #Returns a collapsed array as 1D\n",
    "\n",
    "        if significance:\n",
    "            intervals = np.zeros((X_test.shape[0], 2)) #Creates empty 2D numpy array for saving prediction intervals\n",
    "            err_dist = self.apply_inverse(conformity_scores, significance) #Applies inverse of nonconformity scores\n",
    "            err_dist = np.hstack([err_dist] * n_test) ##Stack arrays in sequence horizontally (column wise)\n",
    "            err_dist *= norm\n",
    "\n",
    "            intervals[:, 0] = test_predictions - err_dist[0, :] #[0] creates lower boundary of the prediction interval\n",
    "            intervals[:, 1] = test_predictions + err_dist[1, :] #[1] creates upper boundary of the prediction interval\n",
    "        \n",
    "            print(\"Prediction Intervals Created\")\n",
    "\n",
    "            return intervals\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Evaluation_Class'></a>\n",
    "## Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #########################\n",
    "    ## Efficiency Measures ##\n",
    "    #########################\n",
    "    def prediction_size(self, predictions):\n",
    "        \"\"\"\n",
    "        Calculates the general and average prediction interval size \n",
    "        based on a conformal prediction regression model.\n",
    "        \n",
    "        @params\n",
    "        prediction_intervals: Prediction Intervals determined from the test patterns\n",
    "        \n",
    "        returns:\n",
    "        \n",
    "        Interval Size: Array that contains the size of the predicted intervals\n",
    "        \"\"\"\n",
    "        interval_size = predictions[:, 1] - predictions[:, 0] #Efficiency measure\n",
    "        mean_size = np.mean(interval_size)\n",
    "        \n",
    "        return interval_size, mean_size    \n",
    "    \n",
    "    def evaluation_table(self, predictions, size, y):\n",
    "        '''\n",
    "        Gives a final table that contains the prediction intervals, their size\n",
    "        and original (true) labels of the test patterns. \n",
    "        Allows to determine efficiency of predictions\n",
    "        \n",
    "        @params\n",
    "        predictions: Prediction intervals determined from the test patterns\n",
    "        size: Size of the respective prediction intervals\n",
    "        y: array of the true labels (i.e. y_test)\n",
    "        \n",
    "        returns:\n",
    "        \n",
    "        Tabulated results for the evaluation function\n",
    "        ''' \n",
    "        header = ['Min','Max','Original Label','Interval Size']\n",
    "        table = np.vstack([predictions.T, y, size.T]).T\n",
    "        predictions_table = pd.DataFrame(table, columns = header)\n",
    "\n",
    "        return predictions_table\n",
    "\n",
    "\n",
    "    #########################\n",
    "    ## Validity Measures ####\n",
    "    #########################\n",
    "    \n",
    "    def correct_predictions(self, predictions, y_test, significance = None):\n",
    "        \"\"\"\n",
    "        Calculates the number of correct predictions (error rate) made by\n",
    "        the conformal functions in a regression model and its average error rate.\n",
    "        \n",
    "        @params\n",
    "        predictions: Prediction intervals determined from the test patterns\n",
    "        y: array of the true labels (i.e. y_test)\n",
    "        significance: Float value between 0-1 (i.e. 0.05)\n",
    "        \"\"\"\n",
    "        \n",
    "        idx = int(significance * 100 - 1)\n",
    "        prediction = predictions[:idx]\n",
    "        \n",
    "        low = y_test >= predictions[:, 0]\n",
    "        high = y_test <= predictions[:, 1]\n",
    "        correct = low * high\n",
    "        \n",
    "        predictions_rate = y_test[correct].size\n",
    "        avg_error_rate = 1 - predictions_rate / y_test.size\n",
    "\n",
    "        return predictions_rate, avg_error_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Functions and Class Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Environments and Model\n",
    "<a id='Loading_Model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and Models have been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator PLSRegression from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = \".env\"\n",
    "model = model_prep(env) #Establish underying ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Setup\n",
    "<a id='data_setup'></a>\n",
    "* Divide training data into two subsets (proper training and calibration data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split\n",
      "X_train and y_train shape: (11694, 3)(11694,)\n",
      "X_cal and y_cal shape: (2924, 3)(2924,)\n",
      "11694 instances, 3 features, 10554 classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_host</th>\n",
       "      <th>split</th>\n",
       "      <th>sequence</th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>--AQVPYGVSQIKAPALH-SQGYTGQNVKVAVIDTGIDSSHEDLKV...</td>\n",
       "      <td>0.039268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>--ASVPYGVSQIKAPALH-SQGYTGSNVKVAVIDSGIDSSHPDLKV...</td>\n",
       "      <td>0.039268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>-ALVVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLWI...</td>\n",
       "      <td>0.261457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>-ALVVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLWI...</td>\n",
       "      <td>0.265189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>-AQAVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHGDLNI...</td>\n",
       "      <td>0.419681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_host  split                                           sequence  \\\n",
       "0     False  train  --AQVPYGVSQIKAPALH-SQGYTGQNVKVAVIDTGIDSSHEDLKV...   \n",
       "1     False  train  --ASVPYGVSQIKAPALH-SQGYTGSNVKVAVIDSGIDSSHPDLKV...   \n",
       "2     False  train  -ALVVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLWI...   \n",
       "3     False  train  -ALVVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHPDLWI...   \n",
       "4     False  train  -AQAVPWGISRVQAPAAH-NRGLTGSGVKVAVLDTGI-STHGDLNI...   \n",
       "\n",
       "   expression  \n",
       "0    0.039268  \n",
       "1    0.039268  \n",
       "2    0.261457  \n",
       "3    0.265189  \n",
       "4    0.419681  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.read_csv_from_s3(\"s3://mlflow/4/1a163dd9fecc435fbf340dbdd5170cb9/artifacts/dataset.csv\") #Upload dataset from MLFlow\n",
    "X_test, y_test, X_train, y_train, X_cal, y_cal = data_split(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Calibration Procedure\n",
    "* Train the underlying model\n",
    "* Define Non-Conformity function, measure nonconformity of calibration examples and obtain their respective nonconformal scores\n",
    "<a id='training_calibration'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NonConformist(model) #Define NonConformist Class\n",
    "nc.underlying_fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_predictions = nc.calibration_predict(X_cal)\n",
    "conformity_scores = nc.apply_nonconformity(calibration_predictions, y_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Procedure\n",
    "<a id='prediction_procedure'></a>\n",
    "\n",
    "* Produce prediction intervals for the test set, with a confidence of 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_intervals = nc.conformal_predictions(X_test, conformity_scores, significance = 0.05)\n",
    "prediction_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficiency and Validity\n",
    "* Conformal predictors are automatically valid\n",
    "* Efficiency depends on the nonconformity function (and thus the underlying model)\n",
    "<a id='efficiency_validity'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = Evaluation()\n",
    "interval_size, mean_size = ev.prediction_size(prediction_intervals)\n",
    "predictions_table = ev.evaluation_table(prediction_intervals, interval_size, y_test)\n",
    "predictions_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev=Evaluation()\n",
    "ev.correct_predictions(prediction_intervals, y_test, significance = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "min_val = prediction_intervals[:, 0]\n",
    "max_val = prediction_intervals[:, 1]\n",
    "true_values = y_test\n",
    "predicted_values = predicted_values\n",
    "plt.plot(min_val, label = \"Min\", color='blue')\n",
    "plt.plot(max_val, label = \"Max\", color='red')\n",
    "#plt.plot(true_values, label = \"y\", color = \"black\")\n",
    "plt.plot(predicted_values, label = \"y\\u0302\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
